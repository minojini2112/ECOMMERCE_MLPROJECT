# streamlit_app.py
import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import numpy as np
import os
import warnings

# Suppress Plotly warnings
warnings.filterwarnings('ignore', category=UserWarning, module='plotly')

# Import your custom modules
try:
    from prediction import MLModelPredictor
    from data_generator import DashboardDataGenerator
    MODELS_AVAILABLE = True
except:
    MODELS_AVAILABLE = False
    st.warning("‚ö† Models not found. Please train models first by running the training pipeline.")

# Page config
st.set_page_config(
    page_title="E-commerce ML Analytics Dashboard",
    page_icon="üõí",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Initialize model predictor and data generator
@st.cache_resource
def load_models():
    if MODELS_AVAILABLE:
        # You'll need to specify the correct model version here
        # Check your models/ directory for the latest version
        model_files = [f for f in os.listdir('models/') if f.startswith('churn_model_')]
        if model_files:
            # Extract version from filename like 'churn_model_20250904_114402.pkl'
            latest_file = sorted(model_files)[-1]
            # Split by '_' and take the last two parts (date_time)
            version_parts = latest_file.replace('churn_model_', '').replace('.pkl', '').split('_')
            latest_version = '_'.join(version_parts)
            print(f"Loading model version: {latest_version}")  # Debug info
            return MLModelPredictor(latest_version)
    return None

@st.cache_resource
def load_data_generator():
    if MODELS_AVAILABLE:
        model_files = [f for f in os.listdir('models/') if f.startswith('churn_model_')]
        if model_files:
            latest_file = sorted(model_files)[-1]
            version_parts = latest_file.replace('churn_model_', '').replace('.pkl', '').split('_')
            latest_version = '_'.join(version_parts)
            return DashboardDataGenerator(latest_version)
    return DashboardDataGenerator()

predictor = load_models()
data_generator = load_data_generator()

# Sidebar navigation
st.sidebar.title("üõí E-commerce ML Analytics")
page = st.sidebar.selectbox("Choose a page", [
    "üìä Overview Dashboard", 
    "üîÆ Customer Prediction", 
    "üë• Customer Segmentation",
    "üìà Model Performance",
    "üéØ Business Insights"
])

if page == "üìä Overview Dashboard":
    st.title("E-commerce Analytics Dashboard")
    st.markdown("---")
    
    # Add refresh button
    col_refresh, col_info = st.columns([1, 4])
    with col_refresh:
        if st.button("üîÑ Refresh Predictions", help="Generate new predictions with fresh data"):
            st.cache_data.clear()
            st.rerun()
    
    with col_info:
        st.info("üìä All metrics below are generated using trained ML models with realistic customer data")
    
    # Generate ML-based metrics
    @st.cache_data(ttl=300)  # Cache for 5 minutes
    def get_dashboard_metrics():
        try:
            return data_generator.get_dashboard_metrics()
        except Exception as e:
            st.error(f"Error generating metrics: {e}")
            # Return fallback metrics
            return {
                'total_customers': "1,000",
                'total_customers_delta': "+100",
                'churn_rate': "15.0%",
                'churn_rate_delta': "-2.0%",
                'avg_clv': "$150.00",
                'avg_clv_delta': "$10.00",
                'model_accuracy': "95.0%",
                'model_accuracy_delta': "1.0%",
                'segment_distribution': {'Champions': 0.3, 'Loyal Customers': 0.4, 'Potential Loyalists': 0.2, 'At Risk': 0.1},
                'clv_distribution': np.random.lognormal(4.5, 1.2, 1000).tolist()
            }
    
    metrics = get_dashboard_metrics()
    
    # Key metrics row
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric(
            label="Total Customers",
            value=metrics['total_customers'],
            delta=metrics['total_customers_delta']
        )
    
    with col2:
        st.metric(
            label="Churn Rate",
            value=metrics['churn_rate'],
            delta=metrics['churn_rate_delta']
        )
    
    with col3:
        st.metric(
            label="Avg CLV",
            value=metrics['avg_clv'],
            delta=metrics['avg_clv_delta']
        )
    
    with col4:
        st.metric(
            label="Model Accuracy",
            value=metrics['model_accuracy'],
            delta=metrics['model_accuracy_delta']
        )
    
    # Charts row
    col1, col2 = st.columns(2)
    
    with col1:
        # Customer segmentation pie chart using ML predictions
        segment_dist = metrics['segment_distribution']
        segments = list(segment_dist.keys())
        values = [int(v * 100) for v in segment_dist.values()]  # Convert to percentages
        
        # Create pie chart with error handling
        try:
            fig_pie = px.pie(values=values, names=segments, 
                            title="Customer Segmentation Distribution (ML-Predicted)")
            st.plotly_chart(fig_pie, use_container_width=True)
        except Exception as e:
            st.error(f"Error creating pie chart: {e}")
            # Fallback to bar chart
            fig_bar = px.bar(x=segments, y=values, 
                            title="Customer Segmentation Distribution (ML-Predicted)")
            fig_bar.update_layout(xaxis_title="Customer Segment", yaxis_title="Percentage")
            st.plotly_chart(fig_bar, use_container_width=True)
    
    with col2:
        # CLV distribution histogram using ML predictions
        clv_data = metrics['clv_distribution']
        fig_hist = px.histogram(x=clv_data, nbins=50, 
                               title="Customer Lifetime Value Distribution (ML-Predicted)")
        fig_hist.update_layout(
            xaxis_title="CLV ($)",
            yaxis_title="Number of Customers"
        )
        st.plotly_chart(fig_hist, use_container_width=True)

elif page == "üîÆ Customer Prediction":
    st.title("Customer Prediction Tool")
    st.markdown("---")
    
    if not predictor:
        st.error("‚ùå Models not available. Please train models first.")
        st.stop()
    
    # Input form
    with st.form("prediction_form"):
        st.subheader("Enter Customer Information")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            recency = st.number_input("Recency (days)", min_value=0, max_value=500, value=30)
            frequency = st.number_input("Frequency (orders)", min_value=1, max_value=50, value=5)
            monetary = st.number_input("Monetary ($)", min_value=0.0, max_value=10000.0, value=500.0)
        
        with col2:
            avg_order_value = st.number_input("Avg Order Value ($)", min_value=0.0, max_value=2000.0, value=100.0)
            pct_card = st.slider("Credit Card Usage (%)", 0.0, 1.0, 0.7, 0.01)
            avg_installments = st.number_input("Avg Installments", min_value=1.0, max_value=24.0, value=2.0)
        
        with col3:
            avg_review = st.slider("Average Review Score", 1.0, 5.0, 4.0, 0.1)
            n_categories = st.number_input("Number of Categories", min_value=1, max_value=20, value=3)
        
        submitted = st.form_submit_button("üîÆ Make Predictions")
        
        if submitted:
            # Prepare input data
            customer_data = {
                'recency': recency,
                'frequency': frequency,
                'monetary': monetary,
                'avg_order_value': avg_order_value,
                'pct_card': pct_card,
                'avg_installments': avg_installments,
                'avg_review': avg_review,
                'n_categories': n_categories
            }
            
            try:
                # Make predictions
                churn_result = predictor.predict_churn(customer_data)
                clv_result = predictor.predict_clv(customer_data)
                segment_result = predictor.predict_segment(customer_data)
                
                # Display results
                st.markdown("---")
                st.subheader("üéØ Prediction Results")
                
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    st.metric(
                        label="Churn Risk",
                        value=f"{churn_result['churn_probability']:.1%}",
                        delta=churn_result['risk_level']
                    )
                    
                    # Churn risk gauge
                    fig_gauge = go.Figure(go.Indicator(
                        mode = "gauge+number",
                        value = churn_result['churn_probability'] * 100,
                        domain = {'x': [0, 1], 'y': [0, 1]},
                        title = {'text': "Churn Risk (%)"},
                        gauge = {
                            'axis': {'range': [None, 100]},
                            'bar': {'color': "darkblue"},
                            'steps': [
                                {'range': [0, 30], 'color': "lightgray"},
                                {'range': [30, 70], 'color': "gray"},
                                {'range': [70, 100], 'color': "lightcoral"}
                            ],
                            'threshold': {
                                'line': {'color': "red", 'width': 4},
                                'thickness': 0.75,
                                'value': 90
                            }
                        }
                    ))
                    st.plotly_chart(fig_gauge, use_container_width=True)
                
                with col2:
                    st.metric(
                        label="Predicted CLV",
                        value=f"${clv_result['predicted_clv']:.2f}",
                        delta=clv_result['clv_category']
                    )
                
                with col3:
                    st.metric(
                        label="Customer Segment",
                        value=segment_result['segment_name'],
                        delta=f"Segment {segment_result['segment_id']}"
                    )
            except Exception as e:
                st.error(f"Error making predictions: {e}")
elif page == "üìà Model Performance":
    st.title("Model Performance Analysis")
    st.markdown("---")
    
    # Add refresh button
    col_refresh, col_info = st.columns([1, 4])
    with col_refresh:
        if st.button("üîÑ Refresh Performance", help="Reload model performance metrics"):
            st.cache_data.clear()
            st.rerun()
    
    with col_info:
        st.info("üìà All performance metrics below are from actual trained ML models")
    
    # Get ML-based performance metrics
    @st.cache_data(ttl=600)  # Cache for 10 minutes
    def get_performance_metrics():
        return data_generator.get_model_performance_metrics()
    
    perf_metrics = get_performance_metrics()
    
    # Model comparison table using actual model performance
    models_data = perf_metrics['models']
    model_data = {
        'Model': list(models_data.keys()),
        'Accuracy': [f"{models_data[model]['accuracy']:.3f}" for model in models_data.keys()],
        'Precision': [f"{models_data[model]['precision']:.3f}" for model in models_data.keys()],
        'Recall': [f"{models_data[model]['recall']:.3f}" for model in models_data.keys()],
        'F1-Score': [f"{models_data[model]['f1_score']:.3f}" for model in models_data.keys()]
    }
    
    df_models = pd.DataFrame(model_data)
    st.subheader("üìä Model Comparison (Actual Performance)")
    st.dataframe(df_models, use_container_width=True)
    
    # Performance charts
    col1, col2 = st.columns(2)
    
    with col1:
        # Convert back to numeric for plotting
        accuracy_values = [float(models_data[model]['accuracy']) for model in models_data.keys()]
        fig_bar = px.bar(x=list(models_data.keys()), y=accuracy_values, 
                        title="Model Accuracy Comparison (ML-Predicted)")
        fig_bar.update_layout(xaxis_title="Model", yaxis_title="Accuracy")
        st.plotly_chart(fig_bar, use_container_width=True)
    
    with col2:
        # Feature importance from actual model metadata
        feature_importance = perf_metrics['feature_importance']
        features = list(feature_importance.keys())
        importance = list(feature_importance.values())
        
        fig_importance = px.bar(x=importance, y=features, orientation='h',
                               title="Feature Importance Analysis (ML-Derived)")
        fig_importance.update_layout(xaxis_title="Importance", yaxis_title="Features")
        st.plotly_chart(fig_importance, use_container_width=True)
    
    # Additional performance metrics
    st.subheader("üìä Additional Performance Metrics")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric(
            label="CLV Model RMSE",
            value=f"${perf_metrics['clv_rmse']:.2f}",
            help="Root Mean Square Error for Customer Lifetime Value predictions"
        )
    
    with col2:
        best_model = max(models_data.keys(), key=lambda x: models_data[x]['accuracy'])
        st.metric(
            label="Best Performing Model",
            value=best_model,
            help="Model with highest accuracy"
        )
    
    with col3:
        best_accuracy = max(models_data[model]['accuracy'] for model in models_data.keys())
        st.metric(
            label="Best Accuracy",
            value=f"{best_accuracy:.3f}",
            help="Highest accuracy achieved by any model"
        )

elif page == "üë• Customer Segmentation":
    st.title("Customer Segmentation Analysis")
    st.markdown("---")
    
    # Add refresh button
    col_refresh, col_info = st.columns([1, 4])
    with col_refresh:
        if st.button("üîÑ Refresh Segments", help="Generate new customer segments with fresh data"):
            st.cache_data.clear()
            st.rerun()
    
    with col_info:
        st.info("üë• All segmentation results below are generated using trained K-means clustering models")
    
    # Generate ML-based segmentation analysis
    @st.cache_data(ttl=300)  # Cache for 5 minutes
    def get_segmentation_analysis():
        # Generate sample customers and get their segment predictions
        customers_df = data_generator.generate_sample_customers(1000)
        segment_analysis = []
        
        for _, customer in customers_df.iterrows():
            try:
                if data_generator.predictor:
                    pred = data_generator.predictor.predict_all(customer.to_dict())
                    segment_analysis.append({
                        'segment': pred['segment']['segment_name'],
                        'clv': pred['clv']['predicted_clv'],
                        'churn_risk': pred['churn']['risk_level'],
                        'churn_prob': pred['churn']['churn_probability']
                    })
                else:
                    # Fallback if no predictor
                    segment_analysis.append({
                        'segment': np.random.choice(['Champions', 'Loyal Customers', 'Potential Loyalists', 'At Risk']),
                        'clv': np.random.lognormal(5, 1),
                        'churn_risk': np.random.choice(['Low', 'Medium', 'High']),
                        'churn_prob': np.random.beta(2, 8)
                    })
            except:
                segment_analysis.append({
                    'segment': 'Unknown',
                    'clv': 100,
                    'churn_risk': 'Medium',
                    'churn_prob': 0.5
                })
        
        return pd.DataFrame(segment_analysis)
    
    segment_df = get_segmentation_analysis()
    
    # Calculate segment characteristics
    segment_stats = segment_df.groupby('segment').agg({
        'clv': ['mean', 'count'],
        'churn_prob': 'mean',
        'churn_risk': lambda x: x.mode().iloc[0] if len(x.mode()) > 0 else 'Medium'
    }).round(2)
    
    segment_stats.columns = ['Avg CLV', 'Count', 'Avg Churn Prob', 'Churn Risk']
    segment_stats['Size (%)'] = (segment_stats['Count'] / len(segment_df) * 100).round(1)
    segment_stats = segment_stats.reset_index()
    segment_stats = segment_stats[['segment', 'Size (%)', 'Avg CLV', 'Churn Risk']]
    segment_stats.columns = ['Segment', 'Size (%)', 'Avg CLV', 'Churn Risk']
    
    # Display analysis
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("Segment Characteristics (ML-Predicted)")
        st.dataframe(segment_stats, use_container_width=True)
        
        # Additional segment insights
        st.subheader("üìä Segment Insights")
        total_customers = len(segment_df)
        at_risk_customers = len(segment_df[segment_df['segment'] == 'At Risk'])
        champions = len(segment_df[segment_df['segment'] == 'Champions'])
        
        col_insight1, col_insight2 = st.columns(2)
        with col_insight1:
            st.metric(
                label="At Risk Customers",
                value=f"{at_risk_customers}",
                delta=f"{(at_risk_customers/total_customers*100):.1f}%"
            )
        
        with col_insight2:
            st.metric(
                label="Champions",
                value=f"{champions}",
                delta=f"{(champions/total_customers*100):.1f}%"
            )
    
    with col2:
        st.subheader("Segment Distribution (ML-Predicted)")
        
        # Pie chart
        segment_counts = segment_df['segment'].value_counts()
        colors = ['gold', 'lightgreen', 'orange', 'lightcoral', 'lightblue']
        
        # Create pie chart with error handling
        try:
            fig = px.pie(values=segment_counts.values, names=segment_counts.index, 
                        title="Customer Segment Distribution (ML-Predicted)",
                        color_discrete_sequence=colors)
            st.plotly_chart(fig, use_container_width=True)
        except Exception as e:
            st.error(f"Error creating pie chart: {e}")
            # Fallback to bar chart
            fig_bar = px.bar(x=segment_counts.index, y=segment_counts.values, 
                            title="Customer Segment Distribution (ML-Predicted)",
                            color=segment_counts.index,
                            color_discrete_sequence=colors)
            fig_bar.update_layout(xaxis_title="Customer Segment", yaxis_title="Count")
            st.plotly_chart(fig_bar, use_container_width=True)
        
        # CLV by segment box plot
        fig_box = px.box(segment_df, x='segment', y='clv', 
                        title="CLV Distribution by Segment (ML-Predicted)")
        fig_box.update_layout(xaxis_title="Customer Segment", yaxis_title="CLV ($)")
        st.plotly_chart(fig_box, use_container_width=True)

elif page == "üéØ Business Insights":
    st.title("Business Insights & Recommendations")
    st.markdown("---")
    
    # Add refresh button
    col_refresh, col_info = st.columns([1, 4])
    with col_refresh:
        if st.button("üîÑ Refresh Insights", help="Generate new business insights with fresh data"):
            st.cache_data.clear()
            st.rerun()
    
    with col_info:
        st.info("üéØ All insights below are generated from ML model predictions and analysis")
    
    # Generate ML-based business insights
    @st.cache_data(ttl=300)  # Cache for 5 minutes
    def get_business_insights():
        return data_generator.get_business_insights()
    
    insights = get_business_insights()
    
    # Get additional performance metrics
    @st.cache_data(ttl=600)
    def get_performance_metrics():
        return data_generator.get_model_performance_metrics()
    
    perf_metrics = get_performance_metrics()
    
    st.subheader("üîç Key Findings (ML-Generated)")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown(f"""
        **Customer Behavior (Based on {insights['total_analyzed']} ML Predictions):**
        - {insights['retention_rate']} of customers do not churn (high retention)
        - Average customer lifetime value: {insights['avg_clv']}
        - {insights['high_value_pct']} of customers are high-value
        - {insights['at_risk_pct']} of customers are at risk of churning
        """)
        
        # Get best performing model
        best_model = max(perf_metrics['models'].keys(), key=lambda x: perf_metrics['models'][x]['accuracy'])
        best_accuracy = perf_metrics['models'][best_model]['accuracy']
        
        st.markdown(f"""
        **Model Performance:**
        - {best_model} achieves {best_accuracy:.1%} accuracy on test set
        - Ridge regression provides CLV predictions with ${perf_metrics['clv_rmse']:.1f} RMSE
        - Feature importance: {list(perf_metrics['feature_importance'].keys())[0]} > {list(perf_metrics['feature_importance'].keys())[1]} > {list(perf_metrics['feature_importance'].keys())[2]}
        """)
    
    with col2:
        # Generate dynamic recommendations based on insights
        at_risk_pct = float(insights['at_risk_pct'].replace('%', ''))
        high_value_pct = float(insights['high_value_pct'].replace('%', ''))
        
        st.markdown(f"""
        **Business Recommendations (ML-Driven):**
        - Focus retention efforts on "At Risk" segment ({insights['at_risk_pct']})
        - Leverage {high_value_pct:.0f}% high-value customers for upselling
        - Implement targeted campaigns based on ML-predicted segments
        - Monitor churn risk using real-time ML predictions
        """)
        
        st.markdown("""
        **Next Steps:**
        - Deploy real-time prediction system
        - A/B test intervention strategies
        - Monitor model performance over time
        - Expand feature engineering with external data
        """)
    
    # Additional ML-based insights
    st.subheader("üìä Advanced ML Insights")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        # Generate sample customers for additional analysis
        sample_customers = data_generator.generate_sample_customers(100)
        if data_generator.predictor:
            predictions = []
            for _, customer in sample_customers.iterrows():
                try:
                    pred = data_generator.predictor.predict_all(customer.to_dict())
                    predictions.append(pred)
                except:
                    continue
            
            if predictions:
                avg_churn_prob = np.mean([p['churn']['churn_probability'] for p in predictions])
                st.metric(
                    label="Average Churn Probability",
                    value=f"{avg_churn_prob:.1%}",
                    help="Based on ML model predictions"
                )
    
    with col2:
        if data_generator.predictor and 'predictions' in locals():
            avg_clv_pred = np.mean([p['clv']['predicted_clv'] for p in predictions])
            st.metric(
                label="Predicted Average CLV",
                value=f"${avg_clv_pred:.2f}",
                help="Based on ML model predictions"
            )
    
    with col3:
        if data_generator.predictor and 'predictions' in locals():
            segment_dist = {}
            for p in predictions:
                seg = p['segment']['segment_name']
                segment_dist[seg] = segment_dist.get(seg, 0) + 1
            
            most_common_segment = max(segment_dist.keys(), key=lambda x: segment_dist[x])
            st.metric(
                label="Most Common Segment",
                value=most_common_segment,
                help="Based on ML clustering predictions"
            )
    
    # Feature importance visualization
    st.subheader("üîç Feature Importance Analysis")
    feature_importance = perf_metrics['feature_importance']
    
    # Create a more detailed feature importance chart
    fig_importance = px.bar(
        x=list(feature_importance.values()), 
        y=list(feature_importance.keys()), 
        orientation='h',
        title="Feature Importance in ML Models",
        labels={'x': 'Importance Score', 'y': 'Features'}
    )
    fig_importance.update_layout(height=400)
    st.plotly_chart(fig_importance, use_container_width=True)
    
    # Model comparison for insights
    st.subheader("ü§ñ Model Performance Comparison")
    models_data = perf_metrics['models']
    
    # Create a comprehensive model comparison
    model_comparison = pd.DataFrame([
        {
            'Model': model,
            'Accuracy': metrics['accuracy'],
            'Precision': metrics['precision'],
            'Recall': metrics['recall'],
            'F1-Score': metrics['f1_score']
        }
        for model, metrics in models_data.items()
    ])
    
    st.dataframe(model_comparison, use_container_width=True)

# Add footer
st.markdown("---")
st.markdown("üí° *Tip*: Use the sidebar to navigate between different analytics views!")